travis_fold:start:worker_info[0K[33;1mWorker information[0m
hostname: b7173031-17fc-4c41-9e02-00cbfc5738f0@1.worker-org-767b688855-wqcn8.gce-production-3
version: v6.2.8 https://github.com/travis-ci/worker/tree/6d3048d96b26562be21fa1a8b8144f4c4cecd083
instance: travis-job-51b7ae27-1725-4cf2-b27a-bd19f887c5dd travis-ci-sardonyx-xenial-1553530528-f909ac5 (via amqp)
startup: 6.132743173s
travis_fold:end:worker_info[0Ktravis_time:start:03047263[0Ktravis_time:end:03047263:start=1581448299095133327,finish=1581448299223971639,duration=128838312,event=no_world_writable_dirs[0Ktravis_time:start:10361c07[0Ktravis_time:end:10361c07:start=1581448299227078939,finish=1581448299234059151,duration=6980212,event=agent[0Ktravis_time:start:052bf96c[0Ktravis_time:end:052bf96c:start=1581448299236947061,finish=1581448299239138339,duration=2191278,event=check_unsupported[0Ktravis_time:start:04ee2ec2[0Ktravis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: python
Build group: stable
Build dist: xenial
Build id: 649072279
Job id: 649072284
Runtime kernel version: 4.15.0-1028-gcp
travis-build version: 08047b878
[34m[1mBuild image provisioning date and time[0m
Mon Mar 25 16:43:24 UTC 2019
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 16.04.6 LTS
Release:	16.04
Codename:	xenial
[34m[1mSystemd Version[0m
systemd 229
[34m[1mCookbooks Version[0m
42e42e4 https://github.com/travis-ci/travis-cookbooks/tree/42e42e4
[34m[1mgit version[0m
git version 2.21.0
[34m[1mbash version[0m
GNU bash, version 4.3.48(1)-release (x86_64-pc-linux-gnu)
[34m[1mgcc version[0m
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609
[34m[1mdocker version[0m
Client:
 Version:           18.06.0-ce
 API version:       1.38
 Go version:        go1.10.3
 Git commit:        0ffa825
 Built:             Wed Jul 18 19:11:02 2018
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.06.0-ce
  API version:      1.38 (minimum version 1.12)
  Go version:       go1.10.3
  Git commit:       0ffa825
  Built:            Wed Jul 18 19:09:05 2018
  OS/Arch:          linux/amd64
  Experimental:     false
[34m[1mclang version[0m
clang version 7.0.0 (tags/RELEASE_700/final)
[34m[1mjq version[0m
jq-1.5
[34m[1mbats version[0m
Bats 0.4.0
[34m[1mshellcheck version[0m
0.6.0
[34m[1mshfmt version[0m
v2.6.3
[34m[1mccache version[0m
3.2.4
[34m[1mcmake version[0m
cmake version 3.12.4
[34m[1mheroku version[0m
heroku/7.22.7 linux-x64 node-v11.10.1
[34m[1mimagemagick version[0m
Version: ImageMagick 6.8.9-9 Q16 x86_64 2018-09-28 http://www.imagemagick.org
[34m[1mmd5deep version[0m
4.4
[34m[1mmercurial version[0m
version 4.8
[34m[1mmysql version[0m
mysql  Ver 14.14 Distrib 5.7.25, for Linux (x86_64) using  EditLine wrapper
[34m[1mopenssl version[0m
OpenSSL 1.0.2g  1 Mar 2016
[34m[1mpacker version[0m
1.3.3
[34m[1mpostgresql client version[0m
psql (PostgreSQL) 10.7 (Ubuntu 10.7-1.pgdg16.04+1)
[34m[1mragel version[0m
Ragel State Machine Compiler version 6.8 Feb 2013
[34m[1msudo version[0m
1.8.16
[34m[1mgzip version[0m
gzip 1.6
[34m[1mzip version[0m
Zip 3.0
[34m[1mvim version[0m
VIM - Vi IMproved 7.4 (2013 Aug 10, compiled Nov 24 2016 16:44:48)
[34m[1miptables version[0m
iptables v1.6.0
[34m[1mcurl version[0m
curl 7.47.0 (x86_64-pc-linux-gnu) libcurl/7.47.0 GnuTLS/3.4.10 zlib/1.2.8 libidn/1.32 librtmp/2.3
[34m[1mwget version[0m
GNU Wget 1.17.1 built on linux-gnu.
[34m[1mrsync version[0m
rsync  version 3.1.1  protocol version 31
[34m[1mgimme version[0m
v1.5.3
[34m[1mnvm version[0m
0.34.0
[34m[1mperlbrew version[0m
/home/travis/perl5/perlbrew/bin/perlbrew  - App::perlbrew/0.86
[34m[1mphpenv version[0m
rbenv 1.1.2
[34m[1mrvm version[0m
rvm 1.29.7 (latest) by Michal Papis, Piotr Kuczynski, Wayne E. Seguin [https://rvm.io]
[34m[1mdefault ruby version[0m
ruby 2.5.3p105 (2018-10-18 revision 65156) [x86_64-linux]
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mElasticSearch version[0m
5.5.0
[34m[1mInstalled Firefox version[0m
firefox 63.0.1
[34m[1mMongoDB version[0m
MongoDB 4.0.7
[34m[1mPhantomJS version[0m
2.1.1
[34m[1mPre-installed PostgreSQL versions[0m
9.4.21
9.5.16
9.6.12
[34m[1mRedis version[0m
redis-server 5.0.4
[34m[1mPre-installed Go versions[0m
1.11.1
[34m[1mmvn version[0m
Apache Maven 3.6.0 (97c98ec64a1fdfee7767ce5ffb20918da4f719f3; 2018-10-24T18:41:47Z)
[34m[1mgradle version[0m
Gradle 4.10.2!
[34m[1mlein version[0m
Leiningen 2.9.1 on Java 11.0.2 OpenJDK 64-Bit Server VM
[34m[1mPre-installed Node.js versions[0m
v10.15.3
v11.0.0
v4.9.1
v6.17.0
v8.12.0
v8.15.1
v8.9
[34m[1mphpenv versions[0m
  system
  5.6
  5.6.40
  7.1
  7.1.27
  7.2
* 7.2.15 (set by /home/travis/.phpenv/version)
  hhvm
  hhvm-stable
[34m[1mcomposer --version[0m
Composer version 1.8.4 2019-02-11 10:52:10
[34m[1mPre-installed Ruby versions[0m
ruby-2.3.8
ruby-2.4.5
ruby-2.5.3
travis_fold:end:system_info[0K
travis_time:end:04ee2ec2:start=1581448299241628402,finish=1581448299247510649,duration=5882247,event=show_system_info[0Ktravis_time:start:0de1bf40[0Ktravis_time:end:0de1bf40:start=1581448299250136656,finish=1581448299261039701,duration=10903045,event=rm_riak_source[0Ktravis_time:start:1ae31605[0Ktravis_time:end:1ae31605:start=1581448299263703891,finish=1581448299268304476,duration=4600585,event=fix_rwky_redis[0Ktravis_time:start:26473b60[0Ktravis_time:end:26473b60:start=1581448299270951642,finish=1581448299616225191,duration=345273549,event=wait_for_network[0Ktravis_time:start:018ccccf[0Ktravis_time:end:018ccccf:start=1581448299619299385,finish=1581448299817837248,duration=198537863,event=update_apt_keys[0Ktravis_time:start:06301eab[0Ktravis_time:end:06301eab:start=1581448299820803576,finish=1581448299868711830,duration=47908254,event=fix_hhvm_source[0Ktravis_time:start:01f31654[0Ktravis_time:end:01f31654:start=1581448299871868831,finish=1581448299874158222,duration=2289391,event=update_mongo_arch[0Ktravis_time:start:008b94fa[0Ktravis_time:end:008b94fa:start=1581448299876670065,finish=1581448299913937063,duration=37266998,event=fix_sudo_enabled_trusty[0Ktravis_time:start:0416b585[0Ktravis_time:end:0416b585:start=1581448299916640862,finish=1581448299918528448,duration=1887586,event=update_glibc[0Ktravis_time:start:189b06ac[0Ktravis_time:end:189b06ac:start=1581448299921144777,finish=1581448299928004531,duration=6859754,event=clean_up_path[0Ktravis_time:start:09641210[0Ktravis_time:end:09641210:start=1581448299930524400,finish=1581448299937358365,duration=6833965,event=fix_resolv_conf[0Ktravis_time:start:0f60fd79[0Ktravis_time:end:0f60fd79:start=1581448299939837541,finish=1581448299947471892,duration=7634351,event=fix_etc_hosts[0Ktravis_time:start:00a26580[0Ktravis_time:end:00a26580:start=1581448299950025740,finish=1581448299958495811,duration=8470071,event=fix_mvn_settings_xml[0Ktravis_time:start:11a3d93e[0Ktravis_time:end:11a3d93e:start=1581448299961137446,finish=1581448299969370798,duration=8233352,event=no_ipv6_localhost[0Ktravis_time:start:051e90e5[0Ktravis_time:end:051e90e5:start=1581448299972004308,finish=1581448299973877152,duration=1872844,event=fix_etc_mavenrc[0Ktravis_time:start:0f8edeb6[0Ktravis_time:end:0f8edeb6:start=1581448299976437632,finish=1581448299979272123,duration=2834491,event=fix_wwdr_certificate[0Ktravis_time:start:1ac5bf90[0Ktravis_time:end:1ac5bf90:start=1581448299981964479,finish=1581448300003160504,duration=21196025,event=put_localhost_first[0Ktravis_time:start:0094a328[0Ktravis_time:end:0094a328:start=1581448300005804434,finish=1581448300008562699,duration=2758265,event=home_paths[0Ktravis_time:start:098fa818[0Ktravis_time:end:098fa818:start=1581448300011154851,finish=1581448300021648867,duration=10494016,event=disable_initramfs[0Ktravis_time:start:14dee086[0Ktravis_time:end:14dee086:start=1581448300024216929,finish=1581448300333587533,duration=309370604,event=disable_ssh_roaming[0Ktravis_time:start:0ed9eaa3[0Ktravis_time:end:0ed9eaa3:start=1581448300336547501,finish=1581448300338558831,duration=2011330,event=debug_tools[0Ktravis_time:start:0a31390e[0Ktravis_time:end:0a31390e:start=1581448300341192412,finish=1581448300343840659,duration=2648247,event=uninstall_oclint[0Ktravis_time:start:00ed0180[0Ktravis_time:end:00ed0180:start=1581448300346486124,finish=1581448300349028220,duration=2542096,event=rvm_use[0Ktravis_time:start:288361f8[0Ktravis_time:end:288361f8:start=1581448300351648348,finish=1581448300358536526,duration=6888178,event=rm_etc_boto_cfg[0Ktravis_time:start:27e9a327[0Ktravis_time:end:27e9a327:start=1581448300361062052,finish=1581448300363724751,duration=2662699,event=rm_oraclejdk8_symlink[0Ktravis_time:start:07123854[0Ktravis_time:end:07123854:start=1581448300366286390,finish=1581448300461560287,duration=95273897,event=enable_i386[0Ktravis_time:start:3524a870[0Ktravis_time:end:3524a870:start=1581448300464564439,finish=1581448300470684380,duration=6119941,event=update_rubygems[0Ktravis_time:start:0d3e84da[0Ktravis_time:end:0d3e84da:start=1581448300473464687,finish=1581448301234522309,duration=761057622,event=ensure_path_components[0Ktravis_time:start:005b1d3c[0Ktravis_time:end:005b1d3c:start=1581448301237433451,finish=1581448301239467012,duration=2033561,event=redefine_curl[0Ktravis_time:start:0744489c[0Ktravis_time:end:0744489c:start=1581448301242029344,finish=1581448301243893568,duration=1864224,event=nonblock_pipe[0Ktravis_time:start:292d08b0[0Ktravis_time:end:292d08b0:start=1581448301246429086,finish=1581448307274763022,duration=6028333936,event=apt_get_update[0Ktravis_time:start:08d25df6[0Ktravis_time:end:08d25df6:start=1581448307277772149,finish=1581448307279828208,duration=2056059,event=deprecate_xcode_64[0Ktravis_time:start:0c63812a[0Ktravis_time:end:0c63812a:start=1581448307282457485,finish=1581448309711729520,duration=2429272035,event=update_heroku[0Ktravis_time:start:0a9b9798[0Ktravis_time:end:0a9b9798:start=1581448309714858240,finish=1581448309716927251,duration=2069011,event=shell_session_update[0Ktravis_time:start:1161c2a8[0Ktravis_fold:start:docker_mtu[0Ktravis_fold:end:docker_mtu[0Ktravis_time:end:1161c2a8:start=1581448309719653186,finish=1581448311958669427,duration=2239016241,event=set_docker_mtu[0Ktravis_time:start:005ec03c[0Ktravis_fold:start:resolvconf[0Ktravis_fold:end:resolvconf[0Ktravis_time:end:005ec03c:start=1581448311962003933,finish=1581448312017091706,duration=55087773,event=resolvconf[0Ktravis_time:start:0687750a[0Ktravis_time:end:0687750a:start=1581448312022485068,finish=1581448312154654127,duration=132169059,event=maven_central_mirror[0Ktravis_time:start:04248981[0Ktravis_time:end:04248981:start=1581448312157655311,finish=1581448312249196014,duration=91540703,event=maven_https[0Ktravis_time:start:1784e098[0Ktravis_time:end:1784e098:start=1581448312256782170,finish=1581448312259148374,duration=2366204,event=fix_ps4[0Ktravis_time:start:027a6b9f[0K
travis_fold:start:git.checkout[0Ktravis_time:start:2491ee81[0K$ git clone --depth=50 --branch=spark_update https://github.com/Ibotta/sk-dist.git Ibotta/sk-dist
Cloning into 'Ibotta/sk-dist'...
remote: Enumerating objects: 30, done.[K
remote: Counting objects:   3% (1/30)[Kremote: Counting objects:   6% (2/30)[Kremote: Counting objects:  10% (3/30)[Kremote: Counting objects:  13% (4/30)[Kremote: Counting objects:  16% (5/30)[Kremote: Counting objects:  20% (6/30)[Kremote: Counting objects:  23% (7/30)[Kremote: Counting objects:  26% (8/30)[Kremote: Counting objects:  30% (9/30)[Kremote: Counting objects:  33% (10/30)[Kremote: Counting objects:  36% (11/30)[Kremote: Counting objects:  40% (12/30)[Kremote: Counting objects:  43% (13/30)[Kremote: Counting objects:  46% (14/30)[Kremote: Counting objects:  50% (15/30)[Kremote: Counting objects:  53% (16/30)[Kremote: Counting objects:  56% (17/30)[Kremote: Counting objects:  60% (18/30)[Kremote: Counting objects:  63% (19/30)[Kremote: Counting objects:  66% (20/30)[Kremote: Counting objects:  70% (21/30)[Kremote: Counting objects:  73% (22/30)[Kremote: Counting objects:  76% (23/30)[Kremote: Counting objects:  80% (24/30)[Kremote: Counting objects:  83% (25/30)[Kremote: Counting objects:  86% (26/30)[Kremote: Counting objects:  90% (27/30)[Kremote: Counting objects:  93% (28/30)[Kremote: Counting objects:  96% (29/30)[Kremote: Counting objects: 100% (30/30)[Kremote: Counting objects: 100% (30/30), done.[K
remote: Compressing objects:   4% (1/24)[Kremote: Compressing objects:   8% (2/24)[Kremote: Compressing objects:  12% (3/24)[Kremote: Compressing objects:  16% (4/24)[Kremote: Compressing objects:  20% (5/24)[Kremote: Compressing objects:  25% (6/24)[Kremote: Compressing objects:  29% (7/24)[Kremote: Compressing objects:  33% (8/24)[Kremote: Compressing objects:  37% (9/24)[Kremote: Compressing objects:  41% (10/24)[Kremote: Compressing objects:  45% (11/24)[Kremote: Compressing objects:  50% (12/24)[Kremote: Compressing objects:  54% (13/24)[Kremote: Compressing objects:  58% (14/24)[Kremote: Compressing objects:  62% (15/24)[Kremote: Compressing objects:  66% (16/24)[Kremote: Compressing objects:  70% (17/24)[Kremote: Compressing objects:  75% (18/24)[Kremote: Compressing objects:  79% (19/24)[Kremote: Compressing objects:  83% (20/24)[Kremote: Compressing objects:  87% (21/24)[Kremote: Compressing objects:  91% (22/24)[Kremote: Compressing objects:  95% (23/24)[Kremote: Compressing objects: 100% (24/24)[Kremote: Compressing objects: 100% (24/24), done.[K
Receiving objects:   0% (1/299)   Receiving objects:   1% (3/299)   Receiving objects:   2% (6/299)   Receiving objects:   3% (9/299)   Receiving objects:   4% (12/299)   Receiving objects:   5% (15/299)   Receiving objects:   6% (18/299)   Receiving objects:   7% (21/299)   Receiving objects:   8% (24/299)   Receiving objects:   9% (27/299)   Receiving objects:  10% (30/299)   Receiving objects:  11% (33/299)   Receiving objects:  12% (36/299)   Receiving objects:  13% (39/299)   Receiving objects:  14% (42/299)   Receiving objects:  15% (45/299)   Receiving objects:  16% (48/299)   Receiving objects:  17% (51/299)   Receiving objects:  18% (54/299)   Receiving objects:  19% (57/299)   Receiving objects:  20% (60/299)   Receiving objects:  21% (63/299)   Receiving objects:  22% (66/299)   Receiving objects:  23% (69/299)   Receiving objects:  24% (72/299)   Receiving objects:  25% (75/299)   Receiving objects:  26% (78/299)   Receiving objects:  27% (81/299)   Receiving objects:  28% (84/299)   Receiving objects:  29% (87/299)   Receiving objects:  30% (90/299)   Receiving objects:  31% (93/299)   Receiving objects:  32% (96/299)   Receiving objects:  33% (99/299)   Receiving objects:  34% (102/299)   Receiving objects:  35% (105/299)   Receiving objects:  36% (108/299)   Receiving objects:  37% (111/299)   Receiving objects:  38% (114/299)   Receiving objects:  39% (117/299)   remote: Total 299 (delta 11), reused 12 (delta 6), pack-reused 269[K
Receiving objects:  40% (120/299)   Receiving objects:  41% (123/299)   Receiving objects:  42% (126/299)   Receiving objects:  43% (129/299)   Receiving objects:  44% (132/299)   Receiving objects:  45% (135/299)   Receiving objects:  46% (138/299)   Receiving objects:  47% (141/299)   Receiving objects:  48% (144/299)   Receiving objects:  49% (147/299)   Receiving objects:  50% (150/299)   Receiving objects:  51% (153/299)   Receiving objects:  52% (156/299)   Receiving objects:  53% (159/299)   Receiving objects:  54% (162/299)   Receiving objects:  55% (165/299)   Receiving objects:  56% (168/299)   Receiving objects:  57% (171/299)   Receiving objects:  58% (174/299)   Receiving objects:  59% (177/299)   Receiving objects:  60% (180/299)   Receiving objects:  61% (183/299)   Receiving objects:  62% (186/299)   Receiving objects:  63% (189/299)   Receiving objects:  64% (192/299)   Receiving objects:  65% (195/299)   Receiving objects:  66% (198/299)   Receiving objects:  67% (201/299)   Receiving objects:  68% (204/299)   Receiving objects:  69% (207/299)   Receiving objects:  70% (210/299)   Receiving objects:  71% (213/299)   Receiving objects:  72% (216/299)   Receiving objects:  73% (219/299)   Receiving objects:  74% (222/299)   Receiving objects:  75% (225/299)   Receiving objects:  76% (228/299)   Receiving objects:  77% (231/299)   Receiving objects:  78% (234/299)   Receiving objects:  79% (237/299)   Receiving objects:  80% (240/299)   Receiving objects:  81% (243/299)   Receiving objects:  82% (246/299)   Receiving objects:  83% (249/299)   Receiving objects:  84% (252/299)   Receiving objects:  85% (255/299)   Receiving objects:  86% (258/299)   Receiving objects:  87% (261/299)   Receiving objects:  88% (264/299)   Receiving objects:  89% (267/299)   Receiving objects:  90% (270/299)   Receiving objects:  91% (273/299)   Receiving objects:  92% (276/299)   Receiving objects:  93% (279/299)   Receiving objects:  94% (282/299)   Receiving objects:  95% (285/299)   Receiving objects:  96% (288/299)   Receiving objects:  97% (291/299)   Receiving objects:  98% (294/299)   Receiving objects:  99% (297/299)   Receiving objects: 100% (299/299)   Receiving objects: 100% (299/299), 260.96 KiB | 8.15 MiB/s, done.
Resolving deltas:   0% (0/143)   Resolving deltas:   6% (9/143)   Resolving deltas:  11% (17/143)   Resolving deltas:  13% (19/143)   Resolving deltas:  20% (29/143)   Resolving deltas:  23% (33/143)   Resolving deltas:  25% (36/143)   Resolving deltas:  27% (39/143)   Resolving deltas:  28% (41/143)   Resolving deltas:  34% (49/143)   Resolving deltas:  37% (53/143)   Resolving deltas:  38% (55/143)   Resolving deltas:  41% (59/143)   Resolving deltas:  44% (64/143)   Resolving deltas:  45% (65/143)   Resolving deltas:  46% (66/143)   Resolving deltas:  48% (69/143)   Resolving deltas:  53% (77/143)   Resolving deltas:  54% (78/143)   Resolving deltas:  55% (80/143)   Resolving deltas:  56% (81/143)   Resolving deltas:  57% (82/143)   Resolving deltas:  58% (83/143)   Resolving deltas:  60% (87/143)   Resolving deltas:  61% (88/143)   Resolving deltas:  62% (90/143)   Resolving deltas:  63% (91/143)   Resolving deltas:  65% (94/143)   Resolving deltas:  66% (95/143)   Resolving deltas:  67% (96/143)   Resolving deltas:  68% (98/143)   Resolving deltas:  69% (99/143)   Resolving deltas:  70% (101/143)   Resolving deltas:  71% (102/143)   Resolving deltas:  83% (120/143)   Resolving deltas:  87% (125/143)   Resolving deltas:  88% (126/143)   Resolving deltas:  92% (132/143)   Resolving deltas:  95% (136/143)   Resolving deltas:  96% (138/143)   Resolving deltas:  97% (139/143)   Resolving deltas:  99% (142/143)   Resolving deltas: 100% (143/143)   Resolving deltas: 100% (143/143), done.
travis_time:end:2491ee81:start=1581448312265562401,finish=1581448312910009740,duration=644447339,event=checkout[0K$ cd Ibotta/sk-dist
$ git checkout -qf d28567a9fda93f620d372bd7c564a8d9896c200a
travis_fold:end:git.checkout[0K
travis_time:end:2491ee81:start=1581448312265562401,finish=1581448312918444082,duration=652881681,event=checkout[0Ktravis_time:start:03c48f3b[0K
[33;1mSetting environment variables from .travis.yml[0m
$ export TEST_SUITE=spark_2_3

travis_time:end:03c48f3b:start=1581448312921135589,finish=1581448312926713472,duration=5577883,event=env[0Ktravis_time:start:00b6ff26[0K$ source ~/virtualenv/python3.7/bin/activate
travis_time:end:00b6ff26:start=1581448312929510316,finish=1581448312934161884,duration=4651568,event=[0K$ python --version
Python 3.7.1
$ pip --version
pip 19.0.3 from /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/pip (python 3.7)
Could not locate requirements.txt. Override the install: key in your .travis.yml to install dependencies.
travis_time:start:227c2848[0K$ build_tools/$TEST_SUITE.sh
Obtaining file:///home/travis/build/Ibotta/sk-dist
Collecting scikit-learn>=0.20.0 (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/73/db/7d8204ddba84ab5d1e4fd1af8f82bbe39c589488bee71e45c662f4144010/scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)

[?25hCollecting pandas>=0.17.0 (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/61/af/ceb7523e86753d5643ed00e8c17a42bdcfe819782c3449d9bbbf5d01867a/pandas-1.0.1-cp37-cp37m-manylinux1_x86_64.whl (10.1MB)

[?25hRequirement already satisfied: numpy in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from sk-dist==0.1.8) (1.15.4)
Collecting scipy (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)

[?25hCollecting joblib (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)

[?25hCollecting xgboost>=0.4 (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/c1/24/5fe7237b2eca13ee0cfb100bec8c23f4e69ce9df852a64b0493d49dae4e0/xgboost-0.90-py2.py3-none-manylinux1_x86_64.whl (142.8MB)

[?25hCollecting pyarrow==0.16.0 (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/67/53/6c801d7d15bafade4fac3ec479b48f4c2d1fa52e725b310e326ff1e082b2/pyarrow-0.16.0-cp37-cp37m-manylinux2010_x86_64.whl (63.7MB)

[?25hCollecting pyspark>=2.4.4 (from sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/9a/5a/271c416c1c2185b6cb0151b29a91fff6fcaed80173c8584ff6d20e46b465/pyspark-2.4.5.tar.gz (217.8MB)

[?25hCollecting pytest-spark>=0.4.5 (from sk-dist==0.1.8)
  Downloading https://files.pythonhosted.org/packages/9f/a9/8b4bc6c416bc8875b56e3bd290ce68dc65ad03e7cbfad878477f694525ca/pytest_spark-0.5.2-py3-none-any.whl
Collecting pytz>=2017.2 (from pandas>=0.17.0->sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)

[?25hCollecting python-dateutil>=2.6.1 (from pandas>=0.17.0->sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)

[?25hRequirement already satisfied: six>=1.0.0 in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pyarrow==0.16.0->sk-dist==0.1.8) (1.11.0)
Collecting py4j==0.10.7 (from pyspark>=2.4.4->sk-dist==0.1.8)
[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)

[?25hRequirement already satisfied: pytest in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest-spark>=0.4.5->sk-dist==0.1.8) (4.3.1)
Collecting findspark (from pytest-spark>=0.4.5->sk-dist==0.1.8)
  Downloading https://files.pythonhosted.org/packages/b1/c8/e6e1f6a303ae5122dc28d131b5a67c5eb87cbf8f7ac5b9f87764ea1b1e1e/findspark-1.3.0-py2.py3-none-any.whl
Requirement already satisfied: setuptools in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (40.8.0)
Requirement already satisfied: more-itertools>=4.0.0; python_version > "2.7" in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (4.3.0)
Requirement already satisfied: pluggy>=0.7 in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (0.8.0)
Requirement already satisfied: atomicwrites>=1.0 in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (1.2.1)
Requirement already satisfied: py>=1.5.0 in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (1.7.0)
Requirement already satisfied: attrs>=17.4.0 in /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages (from pytest->pytest-spark>=0.4.5->sk-dist==0.1.8) (18.2.0)
Building wheels for collected packages: pyspark
  Building wheel for pyspark (setup.py) ... [?25l- \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | / - \ | done
[?25h  Stored in directory: /home/travis/.cache/pip/wheels/bf/db/04/61d66a5939364e756eb1c1be4ec5bdce6e04047fc7929a3c3c
Successfully built pyspark
Installing collected packages: scipy, joblib, scikit-learn, pytz, python-dateutil, pandas, xgboost, pyarrow, py4j, pyspark, findspark, pytest-spark, sk-dist
  Running setup.py develop for sk-dist
Successfully installed findspark-1.3.0 joblib-0.14.1 pandas-1.0.1 py4j-0.10.7 pyarrow-0.16.0 pyspark-2.4.5 pytest-spark-0.5.2 python-dateutil-2.8.1 pytz-2019.3 scikit-learn-0.22.1 scipy-1.4.1 sk-dist xgboost-0.90
No broken requirements found.
[1m============================= test session starts ==============================[0m
platform linux -- Python 3.7.1, pytest-4.3.1, py-1.7.0, pluggy-0.8.0
spark version -- Spark 2.3.4 built for Hadoop 2.7.3 | Build flags: -B -Pmesos -Pyarn -Pkubernetes -Psparkr -Pkafka-0-8 -Pflume -Pscala-2.11 -Phadoop-2.7 -Phive -Phive-thriftserver -DzincPort=3036
rootdir: /home/travis/build/Ibotta/sk-dist, inifile:
plugins: spark-0.5.2
[1mcollecting ... [0m[1mcollecting 2 items                                                             [0m[1mcollected 63 items                                                             [0m

skdist/distribute/tests/test_base.py [32m.[0m[32m.[0m[36m                                  [  3%][0m
skdist/distribute/tests/test_defaults.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                       [ 17%][0m
skdist/distribute/tests/test_eliminate.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                          [ 25%][0m
skdist/distribute/tests/test_encoder.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                            [ 33%][0m
skdist/distribute/tests/test_ensemble.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                          [ 42%][0m
skdist/distribute/tests/test_init.py [32m.[0m[36m                                   [ 44%][0m
skdist/distribute/tests/test_multiclass.py [32m.[0m[32m.[0m[32m.[0m[36m                           [ 49%][0m
skdist/distribute/tests/test_predict.py [32m.[0m[36m                                [ 50%][0m
skdist/distribute/tests/test_search.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                             [ 58%][0m
skdist/tests/test_init.py [32m.[0m[36m                                              [ 60%][0m
skdist/tests/test_postprocessing.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                                 [ 66%][0m
skdist/tests/test_preprocessing.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[36m                        [ 88%][0m
skdist/tests/test_spark.py [32m.[0m[32m.[0m[32m.[0m[32m.[0m[32m.[0m[31mF[0m[32m.[0m[36m                                       [100%][0m

=================================== FAILURES ===================================
[31m[1m_________________________________ test_predict _________________________________[0m

spark_session = <pyspark.sql.session.SparkSession object at 0x7f9204bb7550>

[1m    @pytest.mark.skipif("pyspark" not in sys.modules, reason="requires pyspark")[0m
[1m    def test_predict(spark_session):[0m
[1m        sc = spark_session.sparkContext[0m
[1m    [0m
[1m        # simple 2-D numpy features[0m
[1m        data = load_digits()[0m
[1m        X = data["data"][0m
[1m        y = data["target"][0m
[1m        model = LogisticRegression([0m
[1m            solver="liblinear",[0m
[1m            multi_class="auto"[0m
[1m        )[0m
[1m        model.fit(X, y)[0m
[1m    [0m
[1m        # get UDFs with default 'numpy' feature types[0m
[1m>       predict = get_prediction_udf(model, method="predict")[0m

[1m[31mskdist/tests/test_spark.py[0m:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l...,
                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
method = 'predict', feature_type = 'numpy', names = None

[1m    def get_prediction_udf(model, method="predict", feature_type="numpy", names=None):[0m
[1m        """[0m
[1m        Build a vectorized PySpark UDF to apply a sklearn model's `predict` or[0m
[1m        `predict_proba` methods columns in a PySpark DataFrame. Handles[0m
[1m        flexible types of feature data for prediction including 2-D numpy[0m
[1m        arrays ('numpy'), single field text data ('text') and mixed type[0m
[1m        pandas DataFrames ('pandas'). The UDF can then be applied as shown in the[0m
[1m        example below.[0m
[1m    [0m
[1m        NOTE: This function requires pyarrow and pyspark with appropriate[0m
[1m        versions for vectorized pandas UDFs and appropriate spark configuration[0m
[1m        to use pyarrow. Ths requires pyarrow>=0.8.0 and pyspark>=2.3.0.[0m
[1m        Additionally, the spark version must be 2.3 or higher. These requirements[0m
[1m        are not enforced by the sk-dist package at setup time.[0m
[1m    [0m
[1m        Args:[0m
[1m            model (sklearn Estimator): sklearn model to distribute[0m
[1m                predictions with PySpark[0m
[1m            method (str): name of prediction method; either 'predict'[0m
[1m                or 'predict_proba'[0m
[1m            feature_type (str): name of feature type; either 'numpy',[0m
[1m                'pandas' or 'text'[0m
[1m            names (array-like): list of ordered column names[0m
[1m                (only necessary for 'pandas' feature_type[0m
[1m        Returns:[0m
[1m            PySpark pandas UDF (pyspark.sql.functions.pandas_udf)[0m
[1m        Example:[0m
[1m        >>> import pandas as pd[0m
[1m        >>> from sklearn.datasets import load_digits[0m
[1m        >>> from sklearn.linear_model import LogisticRegression[0m
[1m        >>> from pyspark.sql import SparkSession[0m
[1m        >>> spark = ([0m
[1m        >>>     SparkSession[0m
[1m        >>>     .builder[0m
[1m        >>>     .getOrCreate()[0m
[1m        >>>     )[0m
[1m        >>> data = load_digits()[0m
[1m        >>> X = data["data"][0m
[1m        >>> y = data["target"][0m
[1m        >>> model = LogisticRegression()[0m
[1m        >>> model.fit(X, y)[0m
[1m        >>> predict = get_prediction_udf(model, method="predict")[0m
[1m        >>> predict_proba = get_prediction_udf(model, method="predict_proba")[0m
[1m        >>> pdf = pd.DataFrame(X)[0m
[1m        >>> sdf = spark.createDataFrame(pdf)[0m
[1m        >>> cols = [F.col(str(c)) for c in sdf.columns][0m
[1m        >>> prediction_df = ([0m
[1m        >>>     sdf[0m
[1m        >>>     .withColumn("scores", predict_proba(*cols))[0m
[1m        >>>     .withColumn("preds", predict(*cols))[0m
[1m        >>>     .select("preds", "scores")[0m
[1m        >>>     )[0m
[1m        >>> prediction_df.show()[0m
[1m        ... +-----+--------------------+[0m
[1m        ... |preds|              scores|[0m
[1m        ... +-----+--------------------+[0m
[1m        ... |    0|[0.99988026795692...|[0m
[1m        ... |    1|[4.75035277837040...|[0m
[1m        ... |    2|[2.94811218592164...|[0m
[1m        ... |    3|[1.63438595023762...|[0m
[1m        ... |    4|[1.11339868338047...|[0m
[1m        ... |    5|[1.47300432716012...|[0m
[1m        ... |    6|[1.08560009259480...|[0m
[1m        ... |    7|[3.02428232165044...|[0m
[1m        ... |    8|[7.65445972596079...|[0m
[1m        ... |    9|[3.97610488897298...|[0m
[1m        ... |    0|[0.99918670844137...|[0m
[1m        ... |    1|[2.65336456879078...|[0m
[1m        ... |    2|[1.85886361541580...|[0m
[1m        ... |    3|[2.89824009324990...|[0m
[1m        ... |    4|[2.84813979824305...|[0m
[1m        ... |    5|[2.70090567992820...|[0m
[1m        ... |    6|[1.10907772018062...|[0m
[1m        ... |    7|[3.06455862370095...|[0m
[1m        ... |    8|[2.38739344440480...|[0m
[1m        ... |    9|[8.23628591704589...|[0m
[1m        ... +-----+--------------------+[0m
[1m        ... only showing top 20 rows[0m
[1m        """[0m
[1m        if not _is_pyspark_installed():[0m
[1m            raise ImportError("Module pyspark not found")[0m
[1m        if not _is_pyarrow_installed():[0m
[1m>           raise ImportError("Module pyarrow not found")[0m
[1m[31mE           ImportError: Module pyarrow not found[0m

[1m[31mskdist/distribute/predict.py[0m:145: ImportError
----------------------------- Captured stderr call -----------------------------
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
[33m=============================== warnings summary ===============================[0m
/home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144
  /home/travis/virtualenv/python3.7.1/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.
    warnings.warn(message, FutureWarning)

/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2020
/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2020
  /opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py:2020: DeprecationWarning: invalid escape sequence \*

/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13
/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13
/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13
/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13
/opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13
  /opt/spark-2.3.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_collections.py:13: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working

/opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/resultiterable.py:23
  /opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/resultiterable.py:23: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
    class ResultIterable(collections.Iterable):

/opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/readwriter.py:427
  /opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/readwriter.py:427: DeprecationWarning: invalid escape sequence \`
    """

/opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/readwriter.py:877
  /opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/readwriter.py:877: DeprecationWarning: invalid escape sequence \`
    """

/opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/streaming.py:653
  /opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/streaming.py:653: DeprecationWarning: invalid escape sequence \`
    """

/opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/functions.py:1633
  /opt/spark-2.3.4-bin-hadoop2.7/python/pyspark/sql/functions.py:1633: DeprecationWarning: invalid escape sequence \d
    """

-- Docs: https://docs.pytest.org/en/latest/warnings.html
[31m[1m============== 1 failed, 62 passed, 13 warnings in 29.62 seconds ===============[0m
travis_time:end:227c2848:start=1581448313690043930,finish=1581448456103747266,duration=142413703336,event=script[0K[31;1mThe command "build_tools/$TEST_SUITE.sh" exited with 1.[0m


Done. Your build exited with 1.
